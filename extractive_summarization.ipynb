{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import networkx as nx\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "import gensim.downloader as api\n",
        "from nltk import word_tokenize, pos_tag\n",
        "import pandas as pd\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import docx as doc\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avo_ROVdigIy",
        "outputId": "1faf700c-49f2-4a52-f15d-85d2297c1450"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S8fxKlCtSLO",
        "outputId": "ec9e18c9-4476-4a1b-e4ee-79ed99969f0a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from python-docx) (4.9.2)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=96919125144479c853942197808d619605d27c1e7424d3a3dfde2783619f26da\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/b8/b2/c4c2b95765e615fe139b0b17b5ea7c0e1b6519b0a9ec8fb34d\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip show networkx"
      ],
      "metadata": {
        "id": "-QOHb0tftV2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade scipy networkx"
      ],
      "metadata": {
        "id": "GO41B9z7o5xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and load the Word2Vec model\n",
        "model = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "I3M8AHBQpHLw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install scipy"
      ],
      "metadata": {
        "id": "-vLIYZmqrt9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install 'networkx<2.7' "
      ],
      "metadata": {
        "id": "TfGIP34MrO_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade scipy networkx"
      ],
      "metadata": {
        "id": "f0st67G8sXzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install 'networkx<2.7'"
      ],
      "metadata": {
        "id": "N6sHy6G4smyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install 'scipy>=1.8'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuwUw3R4stwS",
        "outputId": "8b6ff342-00d3-4d45-d8bf-b84c4e567264"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.8/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy>=1.8) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = doc.Document('Detection of abusive comments.docx').paragraphs\n",
        "lst = []\n",
        "for x in data:\n",
        "  lst.append(x.text)\n",
        "  \n",
        "print(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I8SraCzzIyf",
        "outputId": "573fc847-2f3a-4649-c7bd-167f0b1d57d0"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\t\\t\\tDetection of abusive comments', '\\t\\t\\t\\t\\tChitransh Bose', '\\t\\t\\t\\t      \\t        IIITD', '\\t\\t          Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020', '\\t\\t\\t\\t      ', '\\t\\t\\t\\t             Varun Jhunjhunwala ', '\\t\\t\\t\\t      \\t        IIITD', '\\t\\t        Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020', '\\t\\t\\t                    ', '\\t\\t\\t      \\t                 Ranit Pal ', '\\t\\t\\t\\t                     IIITD', '\\t\\t       Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020', '\\t\\t\\t                   ', '\\t\\t\\t\\t\\t Soumyajyoti DAS ', '\\t\\t\\t\\t                     IIITD', '\\t\\t       Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020', '\\t\\t\\t                   soumyajyoti22075@iiitd.ac.in', '', '', 'Abstract', 'In today’s world where social media is taking an edge over any other source of information and communication, the need for putting appropriate restrictions over it has also increased significantly. People of all ages whether children or elderly people all have the same access to social media sites and micro- blogging sites thus there is a necessity to filter out the comments appropriately. Thus, we are developing a machine learning based model for classifying that if comments done on Twitter are abusive or not. For this we have used various machine learning models and have procured an F1- Score of accuracy of 97.58% using Logistic Regression, 97.66% using SVM and 97.64% using Voting Classifier that is an amalgamation of Logistic regression and SVM.', '', 'Introduction:', '\\tWith the increase in the use of social media sites like Facebook, Instagram and micro-blogging sites like Twitter people are now have more ways to express their views and ideas and have encouraged mass communication significantly. But not all users use the technology in an appropriate ways and use it to express their anger using abusive and derogatory comments. Thus, there should be a mechanism using which we can detect such comments and filter out the abusive comments. Thus, we have proposed a machine learning based model that detects if a comment done is abusive or not. In our work, we have used different machine learning models in order to obtain the model which can determine the comments as abusive and non-abusive efficiently. For this we have used “Hate speech and offensive language dataset” [ 1] consisting of 24,782 samples and 7 features out of which we have extracted features relevant to our work and had modified the labels as per the requirement. This dataset consists of comments obtained from Twitter data and is used to classify the data as hate-speech, offensive and neither. We have modified this dataset as the comments having offensive and non-offensive language and have removed the samples that were hate-speeches.', '', '', '', 'Literature Survey:', '\\tDetermining if a comment on a post is abusive or not is very tedious and difficult tasks and many of the social media sites and platforms are still working to get more accurate and efficient ways to handle such comments. A lot of work is being conducted in this area. Mukul Anand[2] et.al in his paper has used deep learning based model and classified the comments in various categories namely, severe threat, toxic, obscene, insult and identity hate with the help of techniques like CNN, LSTM, etc. Ji Ho Park[3] et al. in their paper has implemented a two- step approach of classification of abusive comments and their classification and has compared it using the traditional single step approach using English Twitter corpus. The detection of comments is not confined to English only and has been done using other languages also like, Muhammad Pervez Akhter[4] et al. in his paper titled “Abusive language detection from social media comments using conventional machine learning and deep learning approaches” have used deep learning based models like CNN, LSTM, BLSTM and CLSTM for detecting abusive comments in Urdu and Roman Urdu languages. Similarly, Tanjim Taharat Aurpa[5] et al. in their paper has proposed an approach to classify the comments in Bengali as an abusive. M. Anand[6] et al. has used feature selection techniques and multilingual offensive language detection using deep learning techniques to classify the language as offensive or not after removing noise, stopwords, from them and performing filtering and segmentation. For feature selection they have Fuzzy based CNN. Monirul Islam Pavel in his work have implemented a CNN and NLP based ensemble method for that performs segmentation on non-toxic and toxic comments in the first phase and then classify them into 6 types, for the preprocessing part they have performed using NLP techniques like tokenization, vectorization, stemming, etc.', '', 'Methodology:', '\\t', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\t\\t         Fig.  1 Framework of the model.', 'In our work, we have various machine learning models for the analysis of the text data and classify them as abusive or non- abusive based on the features obtained after preprocessing the data. For training the data we have used models like Naïve Bayes, SVM, decision tree, logistic regression, random forest. Our framework takes a data as an input and performs the various preprocessing on the data. For the preprocessing part we have done the analysis of the data and removed the features which were not of use for our work. Then we have labelled our data based on the comment if it is abusive or not. Further we have applied NLP techniques for the preprocessing of the dataset. After that the data has been split into the training and testing dataset for cross validation and the training dataset have been trained on various models mentioned above.  Then the testing dataset has been passed to the trained model and the model predicts the output for the testing data along with the evaluation metrics like accuracy, precision, recall and confusion matrix and classification report. After the cross-validation the overall model has been trained on voting classifier and the unknown testing data has been taken in real time from the Twitter using its API and after the preprocessing of the testing data the final predictions are made on the Twitter data. Our framework has been shown in Fig. 1', '', 'Preprocessing:', 'In the preprocessing part we have used NLP technique like lemmatization, lower casing of the sentences, tokenization, have removed unwanted space, removed tags, removed frequent words, removed non-english characters, removed https strings and removed stop words from the dataset.', '', 'Fig.  2 Unprocessed initial data.', '', 'Fig.  3 Data with required features.', '', 'Fig.  4 Processed data.', 'Naïve Bayes', '    We have used Naïve Bayes in our model because it is one of the best known algorithms for text classification and it also doesn’t require much of the dataset to be trained and can be used very well for making real time predictions as it is fast since it is a probability based algorithm based on Bayes theorem. The equation of Bayes Theorem is given in equation 1:', '', '', '\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t         (1)', 'SVM', '   The reason behind using the SVM is that it is very robust and they work very well with higher dimension space, there is also no need of selecting the features in the case of SVM thus, making the classification of text based data easier. For higher dimension space it uses kernel trick and separates the non-linearly separable data in the higher dimension.', 'Decision Tree', '    We have used decision tree because, it requires minimal need of data preprocessing and can be modeled in very less time and is very good for the classification tasks. The text data can have noise present in it.', 'Random Forest', 'To overcome this problem, we have used random forest as it is one of the most suitable algorithms to handle such kind of data as it has a capability to deal with noisy data in the higher dimension space. It takes output of multiple decision trees and based on the voting done on the output of each tree it predicts the output of the data, thus the chance of right predictions are high.', 'Logistic Regression', '    Since we have only two classes that are needed to be predicted and the data we have is linearly separable. It is a very effective and efficient algorithm when we need to perform binary classification and can give a very high accuracy score. It uses sigmoid function to bind the data in the range of 0 to 1.', 'The equation of the sigmoid function is given in equation 2, 3:', '                                              \\t\\t\\t\\t\\t\\t\\t\\t     (2)', 'Where, z = \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t     (3)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t', 'Result and discussion:', 'The models have been trained on the training dataset of 70% of the total dataset and have been cross validated on the 30% of the remaining dataset and has been carried on the system having configuration as Intel® Core™ i5-5200U CPU @ 2.20GHz processor with 8GB RAM and has been trained on “Hate speech and offensive language dataset” of Kaggle[1] that consists of 24,782 samples and 7 features initially and has been filtered as per the requirement. The models have been trained on SVM, Decision Tree, Random Forest, Logistic Regression, Naïve Bayes and has been combined using Voting Classifier with the objects of SVM and Logistic Regression. The datasets are to be classified into two classes abusive and non-abusive. We have chosen Twitter data for the prediction because its API’s are easy to be available and are one of the foremost dataset used in this field. ', 'We have compared our models based on the various evaluation metrics and the formulae are shown in equations 4, 5, 6, 7.', '', '\\t\\t\\t\\t\\t         \\t\\t\\t    (4)', '\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t    (5)', '\\t\\t\\t\\t\\t \\t\\t   \\t\\t\\t    (6)\\t\\t\\t', '\\t\\t\\t\\t    (7)', '', '   Table 1 shows the comparative analysis of the different classifiers used based on the accuracy, precision, recall, F1-score obtained on various models.', '', 'Table 1. Comparative analysis of classifiers based on accuracy, precision, recall, F1-score.', '', 'Table 2 shows the comparative analysis of the different classifiers used based on the TP, TN, FP, FN and accuracy obtained on various models and Fig 5 shows the sample comments obtained from the twitter before preprocessing it.', '', 'Table 2. Comparative analysis of different classifiers based on TP, TN, FP, FN and accuracy.', '', '', 'Fig.  5 Sample comments.', 'Conclusion: ', 'In this project, we have proposed a machine learning based approach for detecting if the comment is of abusive nature or not. Our approach is capable enough of identifying the comments based on its nature into the suitable class with a very high F1-score. We have procured An F1-score of 97.58% using Logistic Regression, 97.66% using SVM, using Decision Tree, 89.95% using Random Forest, 94.57% using Naïve Bayes and 97.64% using Voting Classifier. We can see that the accuracies of Decision Tree and Random Forest are although high (>80%) but still both are not a good classifiers for this dataset as they both are having the problem of accuracy paradox. ', '', 'Individual Contribution:', '1. Chitransh Bose:', '2. Varun Jhunjhunwala:', '3. Ranit Pal:', '4. Soumyajyoti Das:', '', 'References:', '1. Dataset: https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset?resource=download', '2. Mukul Anand; R. Eswari. Classification of Abusive Comments in Social Media using Deep Learning. Published in: 2019 3rd International Conference on Computing Methodologies and Communication (ICCMC), 10.1109/ICCMC.2019.8819734', '3. Ji Ho Park, Pascale Fung. One-step and Two-step Classification for Abusive Language Detection on Twitter. Published in: 1st Workshop on Abusive Languageof the Association of Computational Linguistics (ACL) 2017 (Vancouver, Canada), August 4th, 2017. https://doi.org/10.48550/arXiv.1706.01206', '4. Akhter, M.P., Jiangbin, Z., Naqvi, I.R. et al. Abusive language detection from social media comments using conventional machine learning and deep learning approaches. Multimedia Systems 28, 1925–1940 (2022). https://doi.org/10.1007/s00530-021-00784-8', '5. Aurpa, T.T., Sadik, R. & Ahmed, M.S. Abusive Bangla comments detection on Facebook using transformer-based deep learning models. Soc. Netw. Anal. Min. 12, 24 (2022). https://doi.org/10.1007/s13278-021-00852-x', '6. M. Anand, Kishan Bhushan Sahay, Mohammed Altaf Ahmed, Daniyar Sultan, Radha Raman Chandan, Bharat Singh. Deep learning and natural language processing in computation for offensive language detection in online social networks by feature selection and ensemble classification techniques. ISSN 0304-3975. https://doi.org/10.1016/j.tcs.2022.06.020.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "sentences=[]\n",
        "for i in lst:\n",
        "  sent2=i.split()\n",
        "  for j in sent2:\n",
        "    if j not in stop_words:\n",
        "      sentences.append(j)\n",
        "sentences=sentences[0:2]+sentences[6:]\n",
        "sentence=' '.join(sentences)\n",
        "print(sentence)\n",
        "# sentence = \"I am named John Doe\"\n",
        "tagged_sentence = nltk.tag.pos_tag(sentence.split())\n",
        "edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
        "print()\n",
        "print(' '.join(edited_sentence))\n",
        "sentences=edited_sentence[6:]\n",
        "print(sentences)\n",
        "# I am named\n",
        "token = RegexpTokenizer(r\"\\w+\")\n",
        "sentences=token.tokenize(' '.join(sentences))\n",
        "output = []\n",
        "lst = ['a','r','n','v']\n",
        "wordNetLemmatizer = WordNetLemmatizer()\n",
        "posTag = pos_tag(sentences)\n",
        "\n",
        "for word, tag in posTag:\n",
        "  pos = tag[0].lower()\n",
        "\n",
        "  if pos not in lst:\n",
        "    pos = 'n'\n",
        "  output.append(wordNetLemmatizer.lemmatize(word,pos))\n",
        "print(output)\n",
        "sentences=output\n",
        "print(sentences)\n",
        "# token = RegexpTokenizer(r\"\\w+\")\n",
        "# n=token.tokenize(' '.join(output))\n",
        "# print(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Tlhou8_vfW",
        "outputId": "f8d3d688-4077-4ec2-bcd1-37b11757f57f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection abusive Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020 Varun Jhunjhunwala IIITD Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020 Ranit Pal IIITD Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020 Soumyajyoti DAS IIITD Delhi Okhla Industrial Estate Phase III, New Delhi, India, 110020 soumyajyoti22075@iiitd.ac.in Abstract In today’s world social media taking edge source information communication, need putting appropriate restrictions also increased significantly. People ages whether children elderly people access social media sites micro- blogging sites thus necessity filter comments appropriately. Thus, developing machine learning based model classifying comments done Twitter abusive not. For used various machine learning models procured F1- Score accuracy 97.58% using Logistic Regression, 97.66% using SVM 97.64% using Voting Classifier amalgamation Logistic regression SVM. Introduction: With increase use social media sites like Facebook, Instagram micro-blogging sites like Twitter people ways express views ideas encouraged mass communication significantly. But users use technology appropriate ways use express anger using abusive derogatory comments. Thus, mechanism using detect comments filter abusive comments. Thus, proposed machine learning based model detects comment done abusive not. In work, used different machine learning models order obtain model determine comments abusive non-abusive efficiently. For used “Hate speech offensive language dataset” [ 1] consisting 24,782 samples 7 features extracted features relevant work modified labels per requirement. This dataset consists comments obtained Twitter data used classify data hate-speech, offensive neither. We modified dataset comments offensive non-offensive language removed samples hate-speeches. Literature Survey: Determining comment post abusive tedious difficult tasks many social media sites platforms still working get accurate efficient ways handle comments. A lot work conducted area. Mukul Anand[2] et.al paper used deep learning based model classified comments various categories namely, severe threat, toxic, obscene, insult identity hate help techniques like CNN, LSTM, etc. Ji Ho Park[3] et al. paper implemented two- step approach classification abusive comments classification compared using traditional single step approach using English Twitter corpus. The detection comments confined English done using languages also like, Muhammad Pervez Akhter[4] et al. paper titled “Abusive language detection social media comments using conventional machine learning deep learning approaches” used deep learning based models like CNN, LSTM, BLSTM CLSTM detecting abusive comments Urdu Roman Urdu languages. Similarly, Tanjim Taharat Aurpa[5] et al. paper proposed approach classify comments Bengali abusive. M. Anand[6] et al. used feature selection techniques multilingual offensive language detection using deep learning techniques classify language offensive removing noise, stopwords, performing filtering segmentation. For feature selection Fuzzy based CNN. Monirul Islam Pavel work implemented CNN NLP based ensemble method performs segmentation non-toxic toxic comments first phase classify 6 types, preprocessing part performed using NLP techniques like tokenization, vectorization, stemming, etc. Methodology: Fig. 1 Framework model. In work, various machine learning models analysis text data classify abusive non- abusive based features obtained preprocessing data. For training data used models like Naïve Bayes, SVM, decision tree, logistic regression, random forest. Our framework takes data input performs various preprocessing data. For preprocessing part done analysis data removed features use work. Then labelled data based comment abusive not. Further applied NLP techniques preprocessing dataset. After data split training testing dataset cross validation training dataset trained various models mentioned above. Then testing dataset passed trained model model predicts output testing data along evaluation metrics like accuracy, precision, recall confusion matrix classification report. After cross-validation overall model trained voting classifier unknown testing data taken real time Twitter using API preprocessing testing data final predictions made Twitter data. Our framework shown Fig. 1 Preprocessing: In preprocessing part used NLP technique like lemmatization, lower casing sentences, tokenization, removed unwanted space, removed tags, removed frequent words, removed non-english characters, removed https strings removed stop words dataset. Fig. 2 Unprocessed initial data. Fig. 3 Data required features. Fig. 4 Processed data. Naïve Bayes We used Naïve Bayes model one best known algorithms text classification also doesn’t require much dataset trained used well making real time predictions fast since probability based algorithm based Bayes theorem. The equation Bayes Theorem given equation 1: (1) SVM The reason behind using SVM robust work well higher dimension space, also need selecting features case SVM thus, making classification text based data easier. For higher dimension space uses kernel trick separates non-linearly separable data higher dimension. Decision Tree We used decision tree because, requires minimal need data preprocessing modeled less time good classification tasks. The text data noise present it. Random Forest To overcome problem, used random forest one suitable algorithms handle kind data capability deal noisy data higher dimension space. It takes output multiple decision trees based voting done output tree predicts output data, thus chance right predictions high. Logistic Regression Since two classes needed predicted data linearly separable. It effective efficient algorithm need perform binary classification give high accuracy score. It uses sigmoid function bind data range 0 1. The equation sigmoid function given equation 2, 3: (2) Where, z = (3) Result discussion: The models trained training dataset 70% total dataset cross validated 30% remaining dataset carried system configuration Intel® Core™ i5-5200U CPU @ 2.20GHz processor 8GB RAM trained “Hate speech offensive language dataset” Kaggle[1] consists 24,782 samples 7 features initially filtered per requirement. The models trained SVM, Decision Tree, Random Forest, Logistic Regression, Naïve Bayes combined using Voting Classifier objects SVM Logistic Regression. The datasets classified two classes abusive non-abusive. We chosen Twitter data prediction API’s easy available one foremost dataset used field. We compared models based various evaluation metrics formulae shown equations 4, 5, 6, 7. (4) (5) (6) (7) Table 1 shows comparative analysis different classifiers used based accuracy, precision, recall, F1-score obtained various models. Table 1. Comparative analysis classifiers based accuracy, precision, recall, F1-score. Table 2 shows comparative analysis different classifiers used based TP, TN, FP, FN accuracy obtained various models Fig 5 shows sample comments obtained twitter preprocessing it. Table 2. Comparative analysis different classifiers based TP, TN, FP, FN accuracy. Fig. 5 Sample comments. Conclusion: In project, proposed machine learning based approach detecting comment abusive nature not. Our approach capable enough identifying comments based nature suitable class high F1-score. We procured An F1-score 97.58% using Logistic Regression, 97.66% using SVM, using Decision Tree, 89.95% using Random Forest, 94.57% using Naïve Bayes 97.64% using Voting Classifier. We see accuracies Decision Tree Random Forest although high (>80%) still good classifiers dataset problem accuracy paradox. Individual Contribution: 1. Chitransh Bose: 2. Varun Jhunjhunwala: 3. Ranit Pal: 4. Soumyajyoti Das: References: 1. Dataset: https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset?resource=download 2. Mukul Anand; R. Eswari. Classification Abusive Comments Social Media using Deep Learning. Published in: 2019 3rd International Conference Computing Methodologies Communication (ICCMC), 10.1109/ICCMC.2019.8819734 3. Ji Ho Park, Pascale Fung. One-step Two-step Classification Abusive Language Detection Twitter. Published in: 1st Workshop Abusive Languageof Association Computational Linguistics (ACL) 2017 (Vancouver, Canada), August 4th, 2017. https://doi.org/10.48550/arXiv.1706.01206 4. Akhter, M.P., Jiangbin, Z., Naqvi, I.R. et al. Abusive language detection social media comments using conventional machine learning deep learning approaches. Multimedia Systems 28, 1925–1940 (2022). https://doi.org/10.1007/s00530-021-00784-8 5. Aurpa, T.T., Sadik, R. & Ahmed, M.S. Abusive Bangla comments detection Facebook using transformer-based deep learning models. Soc. Netw. Anal. Min. 12, 24 (2022). https://doi.org/10.1007/s13278-021-00852-x 6. M. Anand, Kishan Bhushan Sahay, Mohammed Altaf Ahmed, Daniyar Sultan, Radha Raman Chandan, Bharat Singh. Deep learning natural language processing computation offensive language detection online social networks feature selection ensemble classification techniques. ISSN 0304-3975. https://doi.org/10.1016/j.tcs.2022.06.020.\n",
            "\n",
            "abusive 110020 110020 110020 110020 soumyajyoti22075@iiitd.ac.in In today’s world social media taking edge source information communication, need putting appropriate restrictions also increased significantly. ages whether children elderly people access social media sites micro- blogging sites thus necessity filter comments appropriately. developing machine learning based model classifying comments done abusive not. For used various machine learning models procured accuracy 97.58% using 97.66% using 97.64% using amalgamation regression With increase use social media sites like micro-blogging sites like people ways express views ideas encouraged mass communication significantly. But users use technology appropriate ways use express anger using abusive derogatory comments. mechanism using detect comments filter abusive comments. proposed machine learning based model detects comment done abusive not. In work, used different machine learning models order obtain model determine comments abusive non-abusive efficiently. For used speech offensive language dataset” [ 1] consisting 24,782 samples 7 features extracted features relevant work modified labels per requirement. This dataset consists comments obtained data used classify data hate-speech, offensive neither. We modified dataset comments offensive non-offensive language removed samples hate-speeches. comment post abusive tedious difficult tasks many social media sites platforms still working get accurate efficient ways handle comments. lot work conducted area. et.al paper used deep learning based model classified comments various categories namely, severe threat, toxic, obscene, insult identity hate help techniques like etc. et al. paper implemented two- step approach classification abusive comments classification compared using traditional single step approach using English corpus. The detection comments confined done using languages also like, et al. paper titled “Abusive language detection social media comments using conventional machine learning deep learning approaches” used deep learning based models like detecting abusive comments languages. et al. paper proposed approach classify comments abusive. et al. used feature selection techniques multilingual offensive language detection using deep learning techniques classify language offensive removing noise, stopwords, performing filtering segmentation. For feature selection based work implemented based ensemble method performs segmentation non-toxic toxic comments first phase classify 6 types, preprocessing part performed using techniques like tokenization, vectorization, stemming, etc. 1 model. In work, various machine learning models analysis text data classify abusive non- abusive based features obtained preprocessing data. For training data used models like decision tree, logistic regression, random forest. Our framework takes data input performs various preprocessing data. For preprocessing part done analysis data removed features use work. Then labelled data based comment abusive not. applied techniques preprocessing dataset. After data split training testing dataset cross validation training dataset trained various models mentioned above. Then testing dataset passed trained model model predicts output testing data along evaluation metrics like accuracy, precision, recall confusion matrix classification report. After cross-validation overall model trained voting classifier unknown testing data taken real time using preprocessing testing data final predictions made data. Our framework shown 1 In preprocessing part used technique like lemmatization, lower casing sentences, tokenization, removed unwanted space, removed tags, removed frequent words, removed non-english characters, removed https strings removed stop words dataset. 2 Unprocessed initial data. 3 required features. 4 Processed data. We used model one best known algorithms text classification also doesn’t require much dataset trained used well making real time predictions fast since probability based algorithm based theorem. The equation given equation 1: (1) The reason behind using robust work well higher dimension space, also need selecting features case thus, making classification text based data easier. For higher dimension space uses kernel trick separates non-linearly separable data higher dimension. We used decision tree because, requires minimal need data preprocessing modeled less time good classification tasks. The text data noise present it. To overcome problem, used random forest one suitable algorithms handle kind data capability deal noisy data higher dimension space. It takes output multiple decision trees based voting done output tree predicts output data, thus chance right predictions high. Logistic Since two classes needed predicted data linearly separable. It effective efficient algorithm need perform binary classification give high accuracy score. It uses sigmoid function bind data range 0 1. The equation sigmoid function given equation 2, 3: (2) discussion: The models trained training dataset 70% total dataset cross validated 30% remaining dataset carried system configuration i5-5200U 2.20GHz processor 8GB trained speech offensive language dataset” consists 24,782 samples 7 features initially filtered per requirement. The models trained combined using objects The datasets classified two classes abusive non-abusive. We chosen data prediction easy available one foremost dataset used field. We compared models based various evaluation metrics formulae shown equations 4, 5, 6, 7. (4) 1 shows comparative analysis different classifiers used based accuracy, precision, recall, obtained various models. Table 1. Comparative analysis classifiers based accuracy, precision, recall, 2 shows comparative analysis different classifiers used based accuracy obtained various models 5 shows sample comments obtained twitter preprocessing it. 2. analysis different classifiers based accuracy. 5 comments. In project, proposed machine learning based approach detecting comment abusive nature not. Our approach capable enough identifying comments based nature suitable class high We procured An F1-score 97.58% using 97.66% using using 89.95% using 94.57% using 97.64% using We see accuracies although high (>80%) still good classifiers dataset problem accuracy paradox. 1. 2. 3. 4. 1. https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset?resource=download 2. using in: 2019 3rd (ICCMC), 10.1109/ICCMC.2019.8819734 3. in: 1st (ACL) 2017 (Vancouver, 4th, 2017. https://doi.org/10.48550/arXiv.1706.01206 4. et al. Abusive language detection social media comments using conventional machine learning deep learning approaches. 28, 1925–1940 (2022). https://doi.org/10.1007/s00530-021-00784-8 5. & comments detection using transformer-based deep learning models. 12, 24 (2022). https://doi.org/10.1007/s13278-021-00852-x 6. learning natural language processing computation offensive language detection online social networks feature selection ensemble classification techniques. 0304-3975. https://doi.org/10.1016/j.tcs.2022.06.020.\n",
            "['In', 'today’s', 'world', 'social', 'media', 'taking', 'edge', 'source', 'information', 'communication,', 'need', 'putting', 'appropriate', 'restrictions', 'also', 'increased', 'significantly.', 'ages', 'whether', 'children', 'elderly', 'people', 'access', 'social', 'media', 'sites', 'micro-', 'blogging', 'sites', 'thus', 'necessity', 'filter', 'comments', 'appropriately.', 'developing', 'machine', 'learning', 'based', 'model', 'classifying', 'comments', 'done', 'abusive', 'not.', 'For', 'used', 'various', 'machine', 'learning', 'models', 'procured', 'accuracy', '97.58%', 'using', '97.66%', 'using', '97.64%', 'using', 'amalgamation', 'regression', 'With', 'increase', 'use', 'social', 'media', 'sites', 'like', 'micro-blogging', 'sites', 'like', 'people', 'ways', 'express', 'views', 'ideas', 'encouraged', 'mass', 'communication', 'significantly.', 'But', 'users', 'use', 'technology', 'appropriate', 'ways', 'use', 'express', 'anger', 'using', 'abusive', 'derogatory', 'comments.', 'mechanism', 'using', 'detect', 'comments', 'filter', 'abusive', 'comments.', 'proposed', 'machine', 'learning', 'based', 'model', 'detects', 'comment', 'done', 'abusive', 'not.', 'In', 'work,', 'used', 'different', 'machine', 'learning', 'models', 'order', 'obtain', 'model', 'determine', 'comments', 'abusive', 'non-abusive', 'efficiently.', 'For', 'used', 'speech', 'offensive', 'language', 'dataset”', '[', '1]', 'consisting', '24,782', 'samples', '7', 'features', 'extracted', 'features', 'relevant', 'work', 'modified', 'labels', 'per', 'requirement.', 'This', 'dataset', 'consists', 'comments', 'obtained', 'data', 'used', 'classify', 'data', 'hate-speech,', 'offensive', 'neither.', 'We', 'modified', 'dataset', 'comments', 'offensive', 'non-offensive', 'language', 'removed', 'samples', 'hate-speeches.', 'comment', 'post', 'abusive', 'tedious', 'difficult', 'tasks', 'many', 'social', 'media', 'sites', 'platforms', 'still', 'working', 'get', 'accurate', 'efficient', 'ways', 'handle', 'comments.', 'lot', 'work', 'conducted', 'area.', 'et.al', 'paper', 'used', 'deep', 'learning', 'based', 'model', 'classified', 'comments', 'various', 'categories', 'namely,', 'severe', 'threat,', 'toxic,', 'obscene,', 'insult', 'identity', 'hate', 'help', 'techniques', 'like', 'etc.', 'et', 'al.', 'paper', 'implemented', 'two-', 'step', 'approach', 'classification', 'abusive', 'comments', 'classification', 'compared', 'using', 'traditional', 'single', 'step', 'approach', 'using', 'English', 'corpus.', 'The', 'detection', 'comments', 'confined', 'done', 'using', 'languages', 'also', 'like,', 'et', 'al.', 'paper', 'titled', '“Abusive', 'language', 'detection', 'social', 'media', 'comments', 'using', 'conventional', 'machine', 'learning', 'deep', 'learning', 'approaches”', 'used', 'deep', 'learning', 'based', 'models', 'like', 'detecting', 'abusive', 'comments', 'languages.', 'et', 'al.', 'paper', 'proposed', 'approach', 'classify', 'comments', 'abusive.', 'et', 'al.', 'used', 'feature', 'selection', 'techniques', 'multilingual', 'offensive', 'language', 'detection', 'using', 'deep', 'learning', 'techniques', 'classify', 'language', 'offensive', 'removing', 'noise,', 'stopwords,', 'performing', 'filtering', 'segmentation.', 'For', 'feature', 'selection', 'based', 'work', 'implemented', 'based', 'ensemble', 'method', 'performs', 'segmentation', 'non-toxic', 'toxic', 'comments', 'first', 'phase', 'classify', '6', 'types,', 'preprocessing', 'part', 'performed', 'using', 'techniques', 'like', 'tokenization,', 'vectorization,', 'stemming,', 'etc.', '1', 'model.', 'In', 'work,', 'various', 'machine', 'learning', 'models', 'analysis', 'text', 'data', 'classify', 'abusive', 'non-', 'abusive', 'based', 'features', 'obtained', 'preprocessing', 'data.', 'For', 'training', 'data', 'used', 'models', 'like', 'decision', 'tree,', 'logistic', 'regression,', 'random', 'forest.', 'Our', 'framework', 'takes', 'data', 'input', 'performs', 'various', 'preprocessing', 'data.', 'For', 'preprocessing', 'part', 'done', 'analysis', 'data', 'removed', 'features', 'use', 'work.', 'Then', 'labelled', 'data', 'based', 'comment', 'abusive', 'not.', 'applied', 'techniques', 'preprocessing', 'dataset.', 'After', 'data', 'split', 'training', 'testing', 'dataset', 'cross', 'validation', 'training', 'dataset', 'trained', 'various', 'models', 'mentioned', 'above.', 'Then', 'testing', 'dataset', 'passed', 'trained', 'model', 'model', 'predicts', 'output', 'testing', 'data', 'along', 'evaluation', 'metrics', 'like', 'accuracy,', 'precision,', 'recall', 'confusion', 'matrix', 'classification', 'report.', 'After', 'cross-validation', 'overall', 'model', 'trained', 'voting', 'classifier', 'unknown', 'testing', 'data', 'taken', 'real', 'time', 'using', 'preprocessing', 'testing', 'data', 'final', 'predictions', 'made', 'data.', 'Our', 'framework', 'shown', '1', 'In', 'preprocessing', 'part', 'used', 'technique', 'like', 'lemmatization,', 'lower', 'casing', 'sentences,', 'tokenization,', 'removed', 'unwanted', 'space,', 'removed', 'tags,', 'removed', 'frequent', 'words,', 'removed', 'non-english', 'characters,', 'removed', 'https', 'strings', 'removed', 'stop', 'words', 'dataset.', '2', 'Unprocessed', 'initial', 'data.', '3', 'required', 'features.', '4', 'Processed', 'data.', 'We', 'used', 'model', 'one', 'best', 'known', 'algorithms', 'text', 'classification', 'also', 'doesn’t', 'require', 'much', 'dataset', 'trained', 'used', 'well', 'making', 'real', 'time', 'predictions', 'fast', 'since', 'probability', 'based', 'algorithm', 'based', 'theorem.', 'The', 'equation', 'given', 'equation', '1:', '(1)', 'The', 'reason', 'behind', 'using', 'robust', 'work', 'well', 'higher', 'dimension', 'space,', 'also', 'need', 'selecting', 'features', 'case', 'thus,', 'making', 'classification', 'text', 'based', 'data', 'easier.', 'For', 'higher', 'dimension', 'space', 'uses', 'kernel', 'trick', 'separates', 'non-linearly', 'separable', 'data', 'higher', 'dimension.', 'We', 'used', 'decision', 'tree', 'because,', 'requires', 'minimal', 'need', 'data', 'preprocessing', 'modeled', 'less', 'time', 'good', 'classification', 'tasks.', 'The', 'text', 'data', 'noise', 'present', 'it.', 'To', 'overcome', 'problem,', 'used', 'random', 'forest', 'one', 'suitable', 'algorithms', 'handle', 'kind', 'data', 'capability', 'deal', 'noisy', 'data', 'higher', 'dimension', 'space.', 'It', 'takes', 'output', 'multiple', 'decision', 'trees', 'based', 'voting', 'done', 'output', 'tree', 'predicts', 'output', 'data,', 'thus', 'chance', 'right', 'predictions', 'high.', 'Logistic', 'Since', 'two', 'classes', 'needed', 'predicted', 'data', 'linearly', 'separable.', 'It', 'effective', 'efficient', 'algorithm', 'need', 'perform', 'binary', 'classification', 'give', 'high', 'accuracy', 'score.', 'It', 'uses', 'sigmoid', 'function', 'bind', 'data', 'range', '0', '1.', 'The', 'equation', 'sigmoid', 'function', 'given', 'equation', '2,', '3:', '(2)', 'discussion:', 'The', 'models', 'trained', 'training', 'dataset', '70%', 'total', 'dataset', 'cross', 'validated', '30%', 'remaining', 'dataset', 'carried', 'system', 'configuration', 'i5-5200U', '2.20GHz', 'processor', '8GB', 'trained', 'speech', 'offensive', 'language', 'dataset”', 'consists', '24,782', 'samples', '7', 'features', 'initially', 'filtered', 'per', 'requirement.', 'The', 'models', 'trained', 'combined', 'using', 'objects', 'The', 'datasets', 'classified', 'two', 'classes', 'abusive', 'non-abusive.', 'We', 'chosen', 'data', 'prediction', 'easy', 'available', 'one', 'foremost', 'dataset', 'used', 'field.', 'We', 'compared', 'models', 'based', 'various', 'evaluation', 'metrics', 'formulae', 'shown', 'equations', '4,', '5,', '6,', '7.', '(4)', '1', 'shows', 'comparative', 'analysis', 'different', 'classifiers', 'used', 'based', 'accuracy,', 'precision,', 'recall,', 'obtained', 'various', 'models.', 'Table', '1.', 'Comparative', 'analysis', 'classifiers', 'based', 'accuracy,', 'precision,', 'recall,', '2', 'shows', 'comparative', 'analysis', 'different', 'classifiers', 'used', 'based', 'accuracy', 'obtained', 'various', 'models', '5', 'shows', 'sample', 'comments', 'obtained', 'twitter', 'preprocessing', 'it.', '2.', 'analysis', 'different', 'classifiers', 'based', 'accuracy.', '5', 'comments.', 'In', 'project,', 'proposed', 'machine', 'learning', 'based', 'approach', 'detecting', 'comment', 'abusive', 'nature', 'not.', 'Our', 'approach', 'capable', 'enough', 'identifying', 'comments', 'based', 'nature', 'suitable', 'class', 'high', 'We', 'procured', 'An', 'F1-score', '97.58%', 'using', '97.66%', 'using', 'using', '89.95%', 'using', '94.57%', 'using', '97.64%', 'using', 'We', 'see', 'accuracies', 'although', 'high', '(>80%)', 'still', 'good', 'classifiers', 'dataset', 'problem', 'accuracy', 'paradox.', '1.', '2.', '3.', '4.', '1.', 'https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset?resource=download', '2.', 'using', 'in:', '2019', '3rd', '(ICCMC),', '10.1109/ICCMC.2019.8819734', '3.', 'in:', '1st', '(ACL)', '2017', '(Vancouver,', '4th,', '2017.', 'https://doi.org/10.48550/arXiv.1706.01206', '4.', 'et', 'al.', 'Abusive', 'language', 'detection', 'social', 'media', 'comments', 'using', 'conventional', 'machine', 'learning', 'deep', 'learning', 'approaches.', '28,', '1925–1940', '(2022).', 'https://doi.org/10.1007/s00530-021-00784-8', '5.', '&', 'comments', 'detection', 'using', 'transformer-based', 'deep', 'learning', 'models.', '12,', '24', '(2022).', 'https://doi.org/10.1007/s13278-021-00852-x', '6.', 'learning', 'natural', 'language', 'processing', 'computation', 'offensive', 'language', 'detection', 'online', 'social', 'networks', 'feature', 'selection', 'ensemble', 'classification', 'techniques.', '0304-3975.', 'https://doi.org/10.1016/j.tcs.2022.06.020.']\n",
            "['In', 'today', 's', 'world', 'social', 'medium', 'take', 'edge', 'source', 'information', 'communication', 'need', 'put', 'appropriate', 'restriction', 'also', 'increase', 'significantly', 'age', 'whether', 'child', 'elderly', 'people', 'access', 'social', 'medium', 'site', 'micro', 'blogging', 'site', 'thus', 'necessity', 'filter', 'comment', 'appropriately', 'develop', 'machine', 'learning', 'base', 'model', 'classify', 'comment', 'do', 'abusive', 'not', 'For', 'use', 'various', 'machine', 'learning', 'model', 'procure', 'accuracy', '97', '58', 'use', '97', '66', 'use', '97', '64', 'use', 'amalgamation', 'regression', 'With', 'increase', 'use', 'social', 'medium', 'site', 'like', 'micro', 'blogging', 'site', 'like', 'people', 'way', 'express', 'view', 'idea', 'encourage', 'mass', 'communication', 'significantly', 'But', 'user', 'use', 'technology', 'appropriate', 'way', 'use', 'express', 'anger', 'use', 'abusive', 'derogatory', 'comment', 'mechanism', 'use', 'detect', 'comment', 'filter', 'abusive', 'comment', 'propose', 'machine', 'learn', 'base', 'model', 'detects', 'comment', 'do', 'abusive', 'not', 'In', 'work', 'use', 'different', 'machine', 'learning', 'model', 'order', 'obtain', 'model', 'determine', 'comment', 'abusive', 'non', 'abusive', 'efficiently', 'For', 'use', 'speech', 'offensive', 'language', 'dataset', '1', 'consist', '24', '782', 'sample', '7', 'feature', 'extract', 'feature', 'relevant', 'work', 'modify', 'label', 'per', 'requirement', 'This', 'dataset', 'consist', 'comment', 'obtain', 'data', 'use', 'classify', 'data', 'hate', 'speech', 'offensive', 'neither', 'We', 'modify', 'dataset', 'comment', 'offensive', 'non', 'offensive', 'language', 'remove', 'sample', 'hate', 'speech', 'comment', 'post', 'abusive', 'tedious', 'difficult', 'task', 'many', 'social', 'medium', 'site', 'platform', 'still', 'work', 'get', 'accurate', 'efficient', 'way', 'handle', 'comment', 'lot', 'work', 'conduct', 'area', 'et', 'al', 'paper', 'use', 'deep', 'learn', 'base', 'model', 'classify', 'comment', 'various', 'category', 'namely', 'severe', 'threat', 'toxic', 'obscene', 'insult', 'identity', 'hate', 'help', 'technique', 'like', 'etc', 'et', 'al', 'paper', 'implement', 'two', 'step', 'approach', 'classification', 'abusive', 'comment', 'classification', 'compare', 'use', 'traditional', 'single', 'step', 'approach', 'use', 'English', 'corpus', 'The', 'detection', 'comment', 'confine', 'do', 'use', 'language', 'also', 'like', 'et', 'al', 'paper', 'title', 'Abusive', 'language', 'detection', 'social', 'medium', 'comment', 'use', 'conventional', 'machine', 'learn', 'deep', 'learning', 'approach', 'use', 'deep', 'learning', 'base', 'model', 'like', 'detect', 'abusive', 'comment', 'languages', 'et', 'al', 'paper', 'propose', 'approach', 'classify', 'comment', 'abusive', 'et', 'al', 'use', 'feature', 'selection', 'technique', 'multilingual', 'offensive', 'language', 'detection', 'use', 'deep', 'learning', 'technique', 'classify', 'language', 'offensive', 'remove', 'noise', 'stopwords', 'perform', 'filter', 'segmentation', 'For', 'feature', 'selection', 'base', 'work', 'implement', 'base', 'ensemble', 'method', 'performs', 'segmentation', 'non', 'toxic', 'toxic', 'comment', 'first', 'phase', 'classify', '6', 'type', 'preprocessing', 'part', 'perform', 'use', 'technique', 'like', 'tokenization', 'vectorization', 'stem', 'etc', '1', 'model', 'In', 'work', 'various', 'machine', 'learning', 'model', 'analysis', 'text', 'data', 'classify', 'abusive', 'non', 'abusive', 'base', 'feature', 'obtain', 'preprocessing', 'data', 'For', 'training', 'data', 'use', 'model', 'like', 'decision', 'tree', 'logistic', 'regression', 'random', 'forest', 'Our', 'framework', 'take', 'data', 'input', 'performs', 'various', 'preprocessing', 'data', 'For', 'preprocessing', 'part', 'do', 'analysis', 'data', 'remove', 'feature', 'use', 'work', 'Then', 'label', 'data', 'base', 'comment', 'abusive', 'not', 'apply', 'technique', 'preprocessing', 'dataset', 'After', 'data', 'split', 'train', 'test', 'dataset', 'cross', 'validation', 'training', 'dataset', 'train', 'various', 'model', 'mention', 'above', 'Then', 'test', 'dataset', 'pass', 'trained', 'model', 'model', 'predict', 'output', 'test', 'data', 'along', 'evaluation', 'metric', 'like', 'accuracy', 'precision', 'recall', 'confusion', 'matrix', 'classification', 'report', 'After', 'cross', 'validation', 'overall', 'model', 'train', 'vote', 'classifier', 'unknown', 'testing', 'data', 'take', 'real', 'time', 'use', 'preprocessing', 'test', 'data', 'final', 'prediction', 'make', 'data', 'Our', 'framework', 'show', '1', 'In', 'preprocessing', 'part', 'use', 'technique', 'like', 'lemmatization', 'lower', 'casing', 'sentence', 'tokenization', 'remove', 'unwanted', 'space', 'remove', 'tag', 'remove', 'frequent', 'word', 'remove', 'non', 'english', 'character', 'remove', 'http', 'string', 'remove', 'stop', 'word', 'dataset', '2', 'Unprocessed', 'initial', 'data', '3', 'required', 'feature', '4', 'Processed', 'data', 'We', 'use', 'model', 'one', 'best', 'know', 'algorithm', 'text', 'classification', 'also', 'doesn', 't', 'require', 'much', 'dataset', 'train', 'use', 'well', 'make', 'real', 'time', 'prediction', 'fast', 'since', 'probability', 'base', 'algorithm', 'base', 'theorem', 'The', 'equation', 'give', 'equation', '1', '1', 'The', 'reason', 'behind', 'use', 'robust', 'work', 'well', 'higher', 'dimension', 'space', 'also', 'need', 'select', 'feature', 'case', 'thus', 'make', 'classification', 'text', 'base', 'data', 'easier', 'For', 'higher', 'dimension', 'space', 'use', 'kernel', 'trick', 'separate', 'non', 'linearly', 'separable', 'data', 'higher', 'dimension', 'We', 'use', 'decision', 'tree', 'because', 'require', 'minimal', 'need', 'data', 'preprocessing', 'model', 'le', 'time', 'good', 'classification', 'task', 'The', 'text', 'data', 'noise', 'present', 'it', 'To', 'overcome', 'problem', 'use', 'random', 'forest', 'one', 'suitable', 'algorithm', 'handle', 'kind', 'data', 'capability', 'deal', 'noisy', 'data', 'higher', 'dimension', 'space', 'It', 'take', 'output', 'multiple', 'decision', 'tree', 'base', 'vote', 'do', 'output', 'tree', 'predict', 'output', 'data', 'thus', 'chance', 'right', 'prediction', 'high', 'Logistic', 'Since', 'two', 'class', 'need', 'predict', 'data', 'linearly', 'separable', 'It', 'effective', 'efficient', 'algorithm', 'need', 'perform', 'binary', 'classification', 'give', 'high', 'accuracy', 'score', 'It', 'use', 'sigmoid', 'function', 'bind', 'data', 'range', '0', '1', 'The', 'equation', 'sigmoid', 'function', 'give', 'equation', '2', '3', '2', 'discussion', 'The', 'model', 'train', 'train', 'dataset', '70', 'total', 'dataset', 'cross', 'validate', '30', 'remain', 'dataset', 'carried', 'system', 'configuration', 'i5', '5200U', '2', '20GHz', 'processor', '8GB', 'trained', 'speech', 'offensive', 'language', 'dataset', 'consist', '24', '782', 'sample', '7', 'feature', 'initially', 'filter', 'per', 'requirement', 'The', 'model', 'train', 'combine', 'use', 'object', 'The', 'datasets', 'classify', 'two', 'class', 'abusive', 'non', 'abusive', 'We', 'choose', 'data', 'prediction', 'easy', 'available', 'one', 'foremost', 'dataset', 'use', 'field', 'We', 'compare', 'model', 'base', 'various', 'evaluation', 'metric', 'formulae', 'show', 'equation', '4', '5', '6', '7', '4', '1', 'show', 'comparative', 'analysis', 'different', 'classifier', 'use', 'base', 'accuracy', 'precision', 'recall', 'obtain', 'various', 'model', 'Table', '1', 'Comparative', 'analysis', 'classifier', 'base', 'accuracy', 'precision', 'recall', '2', 'show', 'comparative', 'analysis', 'different', 'classifier', 'use', 'base', 'accuracy', 'obtain', 'various', 'model', '5', 'show', 'sample', 'comment', 'obtain', 'twitter', 'preprocessing', 'it', '2', 'analysis', 'different', 'classifier', 'base', 'accuracy', '5', 'comment', 'In', 'project', 'propose', 'machine', 'learn', 'base', 'approach', 'detect', 'comment', 'abusive', 'nature', 'not', 'Our', 'approach', 'capable', 'enough', 'identify', 'comment', 'base', 'nature', 'suitable', 'class', 'high', 'We', 'procure', 'An', 'F1', 'score', '97', '58', 'use', '97', '66', 'use', 'use', '89', '95', 'use', '94', '57', 'use', '97', '64', 'use', 'We', 'see', 'accuracy', 'although', 'high', '80', 'still', 'good', 'classifier', 'dataset', 'problem', 'accuracy', 'paradox', '1', '2', '3', '4', '1', 'http', 'www', 'kaggle', 'com', 'datasets', 'mrmorj', 'hate', 'speech', 'and', 'offensive', 'language', 'dataset', 'resource', 'download', '2', 'use', 'in', '2019', '3rd', 'ICCMC', '10', '1109', 'ICCMC', '2019', '8819734', '3', 'in', '1st', 'ACL', '2017', 'Vancouver', '4th', '2017', 'http', 'doi', 'org', '10', '48550', 'arXiv', '1706', '01206', '4', 'et', 'al', 'Abusive', 'language', 'detection', 'social', 'medium', 'comment', 'use', 'conventional', 'machine', 'learn', 'deep', 'learning', 'approach', '28', '1925', '1940', '2022', 'http', 'doi', 'org', '10', '1007', 's00530', '021', '00784', '8', '5', 'comment', 'detection', 'use', 'transformer', 'base', 'deep', 'learning', 'model', '12', '24', '2022', 'http', 'doi', 'org', '10', '1007', 's13278', '021', '00852', 'x', '6', 'learning', 'natural', 'language', 'processing', 'computation', 'offensive', 'language', 'detection', 'online', 'social', 'network', 'feature', 'selection', 'ensemble', 'classification', 'technique', '0304', '3975', 'http', 'doi', 'org', '10', '1016', 'j', 'tc', '2022', '06', '020']\n",
            "['In', 'today', 's', 'world', 'social', 'medium', 'take', 'edge', 'source', 'information', 'communication', 'need', 'put', 'appropriate', 'restriction', 'also', 'increase', 'significantly', 'age', 'whether', 'child', 'elderly', 'people', 'access', 'social', 'medium', 'site', 'micro', 'blogging', 'site', 'thus', 'necessity', 'filter', 'comment', 'appropriately', 'develop', 'machine', 'learning', 'base', 'model', 'classify', 'comment', 'do', 'abusive', 'not', 'For', 'use', 'various', 'machine', 'learning', 'model', 'procure', 'accuracy', '97', '58', 'use', '97', '66', 'use', '97', '64', 'use', 'amalgamation', 'regression', 'With', 'increase', 'use', 'social', 'medium', 'site', 'like', 'micro', 'blogging', 'site', 'like', 'people', 'way', 'express', 'view', 'idea', 'encourage', 'mass', 'communication', 'significantly', 'But', 'user', 'use', 'technology', 'appropriate', 'way', 'use', 'express', 'anger', 'use', 'abusive', 'derogatory', 'comment', 'mechanism', 'use', 'detect', 'comment', 'filter', 'abusive', 'comment', 'propose', 'machine', 'learn', 'base', 'model', 'detects', 'comment', 'do', 'abusive', 'not', 'In', 'work', 'use', 'different', 'machine', 'learning', 'model', 'order', 'obtain', 'model', 'determine', 'comment', 'abusive', 'non', 'abusive', 'efficiently', 'For', 'use', 'speech', 'offensive', 'language', 'dataset', '1', 'consist', '24', '782', 'sample', '7', 'feature', 'extract', 'feature', 'relevant', 'work', 'modify', 'label', 'per', 'requirement', 'This', 'dataset', 'consist', 'comment', 'obtain', 'data', 'use', 'classify', 'data', 'hate', 'speech', 'offensive', 'neither', 'We', 'modify', 'dataset', 'comment', 'offensive', 'non', 'offensive', 'language', 'remove', 'sample', 'hate', 'speech', 'comment', 'post', 'abusive', 'tedious', 'difficult', 'task', 'many', 'social', 'medium', 'site', 'platform', 'still', 'work', 'get', 'accurate', 'efficient', 'way', 'handle', 'comment', 'lot', 'work', 'conduct', 'area', 'et', 'al', 'paper', 'use', 'deep', 'learn', 'base', 'model', 'classify', 'comment', 'various', 'category', 'namely', 'severe', 'threat', 'toxic', 'obscene', 'insult', 'identity', 'hate', 'help', 'technique', 'like', 'etc', 'et', 'al', 'paper', 'implement', 'two', 'step', 'approach', 'classification', 'abusive', 'comment', 'classification', 'compare', 'use', 'traditional', 'single', 'step', 'approach', 'use', 'English', 'corpus', 'The', 'detection', 'comment', 'confine', 'do', 'use', 'language', 'also', 'like', 'et', 'al', 'paper', 'title', 'Abusive', 'language', 'detection', 'social', 'medium', 'comment', 'use', 'conventional', 'machine', 'learn', 'deep', 'learning', 'approach', 'use', 'deep', 'learning', 'base', 'model', 'like', 'detect', 'abusive', 'comment', 'languages', 'et', 'al', 'paper', 'propose', 'approach', 'classify', 'comment', 'abusive', 'et', 'al', 'use', 'feature', 'selection', 'technique', 'multilingual', 'offensive', 'language', 'detection', 'use', 'deep', 'learning', 'technique', 'classify', 'language', 'offensive', 'remove', 'noise', 'stopwords', 'perform', 'filter', 'segmentation', 'For', 'feature', 'selection', 'base', 'work', 'implement', 'base', 'ensemble', 'method', 'performs', 'segmentation', 'non', 'toxic', 'toxic', 'comment', 'first', 'phase', 'classify', '6', 'type', 'preprocessing', 'part', 'perform', 'use', 'technique', 'like', 'tokenization', 'vectorization', 'stem', 'etc', '1', 'model', 'In', 'work', 'various', 'machine', 'learning', 'model', 'analysis', 'text', 'data', 'classify', 'abusive', 'non', 'abusive', 'base', 'feature', 'obtain', 'preprocessing', 'data', 'For', 'training', 'data', 'use', 'model', 'like', 'decision', 'tree', 'logistic', 'regression', 'random', 'forest', 'Our', 'framework', 'take', 'data', 'input', 'performs', 'various', 'preprocessing', 'data', 'For', 'preprocessing', 'part', 'do', 'analysis', 'data', 'remove', 'feature', 'use', 'work', 'Then', 'label', 'data', 'base', 'comment', 'abusive', 'not', 'apply', 'technique', 'preprocessing', 'dataset', 'After', 'data', 'split', 'train', 'test', 'dataset', 'cross', 'validation', 'training', 'dataset', 'train', 'various', 'model', 'mention', 'above', 'Then', 'test', 'dataset', 'pass', 'trained', 'model', 'model', 'predict', 'output', 'test', 'data', 'along', 'evaluation', 'metric', 'like', 'accuracy', 'precision', 'recall', 'confusion', 'matrix', 'classification', 'report', 'After', 'cross', 'validation', 'overall', 'model', 'train', 'vote', 'classifier', 'unknown', 'testing', 'data', 'take', 'real', 'time', 'use', 'preprocessing', 'test', 'data', 'final', 'prediction', 'make', 'data', 'Our', 'framework', 'show', '1', 'In', 'preprocessing', 'part', 'use', 'technique', 'like', 'lemmatization', 'lower', 'casing', 'sentence', 'tokenization', 'remove', 'unwanted', 'space', 'remove', 'tag', 'remove', 'frequent', 'word', 'remove', 'non', 'english', 'character', 'remove', 'http', 'string', 'remove', 'stop', 'word', 'dataset', '2', 'Unprocessed', 'initial', 'data', '3', 'required', 'feature', '4', 'Processed', 'data', 'We', 'use', 'model', 'one', 'best', 'know', 'algorithm', 'text', 'classification', 'also', 'doesn', 't', 'require', 'much', 'dataset', 'train', 'use', 'well', 'make', 'real', 'time', 'prediction', 'fast', 'since', 'probability', 'base', 'algorithm', 'base', 'theorem', 'The', 'equation', 'give', 'equation', '1', '1', 'The', 'reason', 'behind', 'use', 'robust', 'work', 'well', 'higher', 'dimension', 'space', 'also', 'need', 'select', 'feature', 'case', 'thus', 'make', 'classification', 'text', 'base', 'data', 'easier', 'For', 'higher', 'dimension', 'space', 'use', 'kernel', 'trick', 'separate', 'non', 'linearly', 'separable', 'data', 'higher', 'dimension', 'We', 'use', 'decision', 'tree', 'because', 'require', 'minimal', 'need', 'data', 'preprocessing', 'model', 'le', 'time', 'good', 'classification', 'task', 'The', 'text', 'data', 'noise', 'present', 'it', 'To', 'overcome', 'problem', 'use', 'random', 'forest', 'one', 'suitable', 'algorithm', 'handle', 'kind', 'data', 'capability', 'deal', 'noisy', 'data', 'higher', 'dimension', 'space', 'It', 'take', 'output', 'multiple', 'decision', 'tree', 'base', 'vote', 'do', 'output', 'tree', 'predict', 'output', 'data', 'thus', 'chance', 'right', 'prediction', 'high', 'Logistic', 'Since', 'two', 'class', 'need', 'predict', 'data', 'linearly', 'separable', 'It', 'effective', 'efficient', 'algorithm', 'need', 'perform', 'binary', 'classification', 'give', 'high', 'accuracy', 'score', 'It', 'use', 'sigmoid', 'function', 'bind', 'data', 'range', '0', '1', 'The', 'equation', 'sigmoid', 'function', 'give', 'equation', '2', '3', '2', 'discussion', 'The', 'model', 'train', 'train', 'dataset', '70', 'total', 'dataset', 'cross', 'validate', '30', 'remain', 'dataset', 'carried', 'system', 'configuration', 'i5', '5200U', '2', '20GHz', 'processor', '8GB', 'trained', 'speech', 'offensive', 'language', 'dataset', 'consist', '24', '782', 'sample', '7', 'feature', 'initially', 'filter', 'per', 'requirement', 'The', 'model', 'train', 'combine', 'use', 'object', 'The', 'datasets', 'classify', 'two', 'class', 'abusive', 'non', 'abusive', 'We', 'choose', 'data', 'prediction', 'easy', 'available', 'one', 'foremost', 'dataset', 'use', 'field', 'We', 'compare', 'model', 'base', 'various', 'evaluation', 'metric', 'formulae', 'show', 'equation', '4', '5', '6', '7', '4', '1', 'show', 'comparative', 'analysis', 'different', 'classifier', 'use', 'base', 'accuracy', 'precision', 'recall', 'obtain', 'various', 'model', 'Table', '1', 'Comparative', 'analysis', 'classifier', 'base', 'accuracy', 'precision', 'recall', '2', 'show', 'comparative', 'analysis', 'different', 'classifier', 'use', 'base', 'accuracy', 'obtain', 'various', 'model', '5', 'show', 'sample', 'comment', 'obtain', 'twitter', 'preprocessing', 'it', '2', 'analysis', 'different', 'classifier', 'base', 'accuracy', '5', 'comment', 'In', 'project', 'propose', 'machine', 'learn', 'base', 'approach', 'detect', 'comment', 'abusive', 'nature', 'not', 'Our', 'approach', 'capable', 'enough', 'identify', 'comment', 'base', 'nature', 'suitable', 'class', 'high', 'We', 'procure', 'An', 'F1', 'score', '97', '58', 'use', '97', '66', 'use', 'use', '89', '95', 'use', '94', '57', 'use', '97', '64', 'use', 'We', 'see', 'accuracy', 'although', 'high', '80', 'still', 'good', 'classifier', 'dataset', 'problem', 'accuracy', 'paradox', '1', '2', '3', '4', '1', 'http', 'www', 'kaggle', 'com', 'datasets', 'mrmorj', 'hate', 'speech', 'and', 'offensive', 'language', 'dataset', 'resource', 'download', '2', 'use', 'in', '2019', '3rd', 'ICCMC', '10', '1109', 'ICCMC', '2019', '8819734', '3', 'in', '1st', 'ACL', '2017', 'Vancouver', '4th', '2017', 'http', 'doi', 'org', '10', '48550', 'arXiv', '1706', '01206', '4', 'et', 'al', 'Abusive', 'language', 'detection', 'social', 'medium', 'comment', 'use', 'conventional', 'machine', 'learn', 'deep', 'learning', 'approach', '28', '1925', '1940', '2022', 'http', 'doi', 'org', '10', '1007', 's00530', '021', '00784', '8', '5', 'comment', 'detection', 'use', 'transformer', 'base', 'deep', 'learning', 'model', '12', '24', '2022', 'http', 'doi', 'org', '10', '1007', 's13278', '021', '00852', 'x', '6', 'learning', 'natural', 'language', 'processing', 'computation', 'offensive', 'language', 'detection', 'online', 'social', 'network', 'feature', 'selection', 'ensemble', 'classification', 'technique', '0304', '3975', 'http', 'doi', 'org', '10', '1016', 'j', 'tc', '2022', '06', '020']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmQqE05viMD6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6-LE5_uiRPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}